# -*- coding: utf-8 -*-
"""LeNet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18u5m7mjWMSUbzgcU1yrZ5KUPFuxZE3Eo
"""

import tensorflow as tf
from tensorflow import keras
from keras import layers, models
import matplotlib.pyplot as plt

tf.config.list_physical_devices('GPU')
mnist_ds = tf.keras.datasets.mnist

(train_images, train_labels), (valid_images, valid_labels) = mnist_ds.load_data()

valid_images, test_images = valid_images[:5000], valid_images[5000:]
valid_labels, test_labels = valid_labels[:5000], valid_labels[5000:]


train_images = train_images.reshape((60000, 28, 28, 1))
valid_images = valid_images.reshape((5000, 28, 28, 1))

model = models.Sequential([
    layers.Conv2D(6, (5, 5), activation='relu', input_shape=(28, 28, 1)),
    layers.AveragePooling2D((2, 2)),
    layers.Conv2D(16, (5, 5), activation='relu'),
    layers.AveragePooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(120, activation='relu'),
    # layers.Dropout(0.1),
    layers.Dense(84, activation='relu'),
    #layers.Dropout(0.1),
    layers.Dense(10, activation='softmax')
    ])

model.compile(optimizer= keras.optimizers.Adam(learning_rate=1e-3),
              loss=keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

model.fit(train_images,
          train_labels,
          batch_size=32,
          epochs=5,
          validation_data=(valid_images, valid_labels))

predictions = model.predict(test_images)
my_accuracy = keras.metrics.Accuracy()
my_accuracy.update_state(predictions.argmax(axis = 1), test_labels)
my_accuracy.result().numpy()

